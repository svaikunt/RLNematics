{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f75aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ReinforcementLearning\n",
    "using ReinforcementLearningExperiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f10d7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /Users/csfloyd/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{BasicDQN <-> CartPole}\n"
      ],
      "text/markdown": [
       "# BasicDQN <-> CartPole\n"
      ],
      "text/plain": [
       "\u001b[1m  BasicDQN <-> CartPole\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:45\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "             \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "         \u001b[38;5;8m200\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠁\u001b[0m⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡆\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;2m⡄\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⣿\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⣷\u001b[0m⠀\u001b[38;5;2m⣿\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⣿\u001b[0m⠀\u001b[38;5;2m⣿\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⢇\u001b[0m\u001b[38;5;2m⣿\u001b[0m⠀\u001b[38;5;2m⣿\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⣿\u001b[0m\u001b[38;5;2m⡀\u001b[0m\u001b[38;5;2m⣿\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score    \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⡸\u001b[0m\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⢹\u001b[0m\u001b[38;5;2m⢿\u001b[0m\u001b[38;5;2m⣿\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⣾\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⠘\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀\u001b[38;5;2m⣾\u001b[0m\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⠗\u001b[0m\u001b[38;5;2m⠚\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢀\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⢠\u001b[0m⠀⠀\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⢠\u001b[0m⠀\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢢\u001b[0m\u001b[38;5;2m⠞\u001b[0m\u001b[38;5;2m⣤\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⠇\u001b[0m\u001b[38;5;2m⡟\u001b[0m\u001b[38;5;2m⢢\u001b[0m\u001b[38;5;2m⢧\u001b[0m\u001b[38;5;2m⡟\u001b[0m\u001b[38;5;2m⡾\u001b[0m\u001b[38;5;2m⡜\u001b[0m\u001b[38;5;2m⠧\u001b[0m\u001b[38;5;2m⡼\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⠁\u001b[0m⠀⠀\u001b[38;5;2m⠁\u001b[0m\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⠁\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀\u001b[38;5;2m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "             \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "             ⠀\u001b[38;5;8m0\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m100\u001b[0m⠀ \n",
      "             ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{BasicDQN <-> CartPole}\n"
      ],
      "text/markdown": [
       "# BasicDQN <-> CartPole\n"
      ],
      "text/plain": [
       "\u001b[1m  BasicDQN <-> CartPole\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "typename(Experiment)\n",
       "├─ policy => typename(ReinforcementLearningCore.Agent)\n",
       "│  ├─ policy => typename(ReinforcementLearningCore.QBasedPolicy)\n",
       "│  │  ├─ learner => typename(ReinforcementLearningZoo.BasicDQNLearner)\n",
       "│  │  │  ├─ approximator => typename(ReinforcementLearningCore.NeuralNetworkApproximator)\n",
       "│  │  │  │  ├─ model => typename(Flux.Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Flux.Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 128×4 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 128-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(NNlib.relu))\n",
       "│  │  │  │  │     ├─ 2\n",
       "│  │  │  │  │     │  └─ typename(Flux.Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 128×128 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 128-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(NNlib.relu))\n",
       "│  │  │  │  │     └─ 3\n",
       "│  │  │  │  │        └─ typename(Flux.Dense)\n",
       "│  │  │  │  │           ├─ weight => 2×128 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 2-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  └─ optimizer => typename(Flux.Optimise.ADAM)\n",
       "│  │  │  │     ├─ eta => 0.001\n",
       "│  │  │  │     ├─ beta\n",
       "│  │  │  │     │  ├─ 1\n",
       "│  │  │  │     │  │  └─ 0.9\n",
       "│  │  │  │     │  └─ 2\n",
       "│  │  │  │     │     └─ 0.999\n",
       "│  │  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │  │     └─ state => typename(IdDict)\n",
       "│  │  │  ├─ loss_func => typename(typeof(Flux.Losses.huber_loss))\n",
       "│  │  │  ├─ γ => 0.99\n",
       "│  │  │  ├─ sampler => typename(ReinforcementLearningCore.BatchSampler)\n",
       "│  │  │  │  ├─ batch_size => 32\n",
       "│  │  │  │  ├─ cache => typename(NamedTuple)\n",
       "│  │  │  │  │  ├─ state => 4×32 Matrix{Float32}\n",
       "│  │  │  │  │  ├─ action => 32-element Vector{Int64}\n",
       "│  │  │  │  │  ├─ reward => 32-element Vector{Float32}\n",
       "│  │  │  │  │  ├─ terminal => 32-element Vector{Bool}\n",
       "│  │  │  │  │  └─ next_state => 4×32 Matrix{Float32}\n",
       "│  │  │  │  └─ rng => typename(Random._GLOBAL_RNG)\n",
       "│  │  │  ├─ min_replay_history => 100\n",
       "│  │  │  ├─ rng => typename(StableRNGs.LehmerRNG)\n",
       "│  │  │  └─ loss => 0.15870401\n",
       "│  │  └─ explorer => typename(ReinforcementLearningCore.EpsilonGreedyExplorer)\n",
       "│  │     ├─ ϵ_stable => 0.01\n",
       "│  │     ├─ ϵ_init => 1.0\n",
       "│  │     ├─ warmup_steps => 0\n",
       "│  │     ├─ decay_steps => 500\n",
       "│  │     ├─ step => 10001\n",
       "│  │     ├─ rng => typename(StableRNGs.LehmerRNG)\n",
       "│  │     └─ is_training => true\n",
       "│  └─ trajectory => typename(ReinforcementLearningCore.Trajectory)\n",
       "│     └─ traces => typename(NamedTuple)\n",
       "│        ├─ state => 4×1001 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        ├─ action => 1001-element CircularArrayBuffers.CircularVectorBuffer{Int64, Vector{Int64}}\n",
       "│        ├─ reward => 1000-element CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}\n",
       "│        └─ terminal => 1000-element CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}\n",
       "├─ env => typename(ReinforcementLearningEnvironments.CartPoleEnv)\n",
       "├─ stop_condition => typename(ReinforcementLearningCore.StopAfterStep)\n",
       "│  ├─ step => 10000\n",
       "│  ├─ cur => 10001\n",
       "│  └─ progress => typename(ProgressMeter.Progress)\n",
       "├─ hook => typename(ReinforcementLearningCore.TotalRewardPerEpisode)\n",
       "│  ├─ rewards => 92-element Vector{Float64}\n",
       "│  ├─ reward => 27.0\n",
       "│  └─ is_display_on_exit => true\n",
       "└─ description => \"# BasicDQN <-> CartPole\"\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(E`JuliaRL_BasicDQN_CartPole`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42069dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ReinforcementLearning\n",
    "using IntervalSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67cc3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Base.OneTo(7)`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "4\n",
       "```\n"
      ],
      "text/plain": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RandomWalk1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eefcf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Int64} with 7 entries:\n",
       "  5 => 2\n",
       "  4 => 2\n",
       "  6 => 2\n",
       "  7 => 2\n",
       "  2 => 2\n",
       "  3 => 2\n",
       "  1 => 2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NS = 7\n",
    "table=Dict(zip(1:NS, fill(2, NS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7789105b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Space{Vector{ClosedInterval{Real}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Space{Vector{ClosedInterval{Real}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be8345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0] in Space(vcat(Space([ClosedInterval(-Inf, Inf) for _ in 1:6])...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4f07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
